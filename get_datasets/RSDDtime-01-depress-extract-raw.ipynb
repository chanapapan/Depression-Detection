{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSDD-Time : Depression users only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n",
      "16\n",
      "25\n",
      "244\n"
     ]
    }
   ],
   "source": [
    "# Preview\n",
    "\n",
    "filepath = f'../OP_datasets/RSDD-Time/RSDD-Time.json'\n",
    "\n",
    "count_current  = 0\n",
    "count_doubt    = 0\n",
    "count_falsepos = 0\n",
    "count_valid = 0\n",
    "\n",
    "import jsonlines\n",
    "with jsonlines.open(filepath) as reader:\n",
    "    for obj in reader:\n",
    "        my_dict = obj\n",
    "        # print(\"user_id = \", my_dict['id'])\n",
    "        # print(\"created date = \", my_dict['created_utc'])\n",
    "    \n",
    "        conditionstatus  = my_dict['consensus']['diagnosis']['conditionstatus']\n",
    "        diagnosisindoubt = my_dict['consensus']['diagnosis']['diagnosisindoubt']\n",
    "        falsepositive    = my_dict['consensus']['diagnosis']['falsepositive']\n",
    "        \n",
    "        if conditionstatus == 1 :\n",
    "            count_current += 1\n",
    "        if diagnosisindoubt == True: \n",
    "            count_doubt += 1\n",
    "        if falsepositive == True: \n",
    "            count_falsepos += 1\n",
    "            \n",
    "        if (conditionstatus == 1) and (diagnosisindoubt == False) and (falsepositive == False):\n",
    "            count_valid += 1\n",
    "        \n",
    "print(count_current)\n",
    "print(count_doubt)\n",
    "print(count_falsepos)\n",
    "print(count_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os \n",
    "import jsonlines\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def save_result_csv( _header_name, _row_data, _path ):\n",
    "    filename    = _path\n",
    "    mode        = 'a' if os.path.exists(filename) else 'w'\n",
    "    with open(f\"{filename}\", mode) as myfile:\n",
    "        fileEmpty   = os.stat(filename).st_size == 0\n",
    "        writer      = csv.DictWriter(myfile, delimiter='|', lineterminator='\\n',fieldnames=_header_name)\n",
    "        if fileEmpty:\n",
    "            writer.writeheader()  # file doesn't exist yet, write a header\n",
    "\n",
    "        row_dic = dict(zip(_header_name, _row_data))\n",
    "        writer.writerow( row_dic )\n",
    "        myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_valid :  244\n",
      "244\n",
      "244\n"
     ]
    }
   ],
   "source": [
    "filepath = f'../OP_datasets/RSDD-Time/RSDD-Time.json'\n",
    "output_path = '../data_time/RSDD_time_user.csv'\n",
    "\n",
    "# get user_id and the date they posted self declared\n",
    "header = ['user_id', 'created_date']\n",
    "\n",
    "count_valid = 0\n",
    "all_user_id = []\n",
    "all_created_date = []\n",
    "\n",
    "with jsonlines.open(filepath) as reader:\n",
    "    \n",
    "    for obj in reader:           \n",
    "        my_dict = obj\n",
    "        \n",
    "        user_id          = my_dict['id']\n",
    "        created_date     = my_dict['created_utc']\n",
    "        conditionstatus  = my_dict['consensus']['diagnosis']['conditionstatus']\n",
    "        diagnosisindoubt = my_dict['consensus']['diagnosis']['diagnosisindoubt']\n",
    "        falsepositive    = my_dict['consensus']['diagnosis']['falsepositive']\n",
    "\n",
    "        if (conditionstatus == 1) and (diagnosisindoubt == False) and (falsepositive == False):\n",
    "            count_valid += 1\n",
    "            all_user_id.append(user_id)\n",
    "            all_created_date.append(created_date)\n",
    "            row = [user_id, created_date]\n",
    "            # save_result_csv( header, row, output_path)\n",
    "        \n",
    "            \n",
    "print(\"count_valid : \", count_valid)\n",
    "print(len(all_user_id))\n",
    "print(len(all_created_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# key = user_id, value = self declare timestamp\n",
    "user_time = { int(id):datetime.fromtimestamp(all_created_date[i]) for i,id in enumerate(all_user_id) }\n",
    "# print(user_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    conditionstatus = 1 'current' : 245 users\n",
    "    diagnosisindoubt = True       : 16 users\n",
    "    falsepositive = True          : 25 users\n",
    "\n",
    "    (conditionstatus == 1) and (diagnosisindoubt == False) and (falsepositive == False) : 244 users !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ALL posts from VALID USERS\n",
    "\n",
    "213 users => 372081 posts\n",
    "\n",
    "(no time filter yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-15d3409aef52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjsonlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mmy_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# dict containing 'id', 'label, 'posts' as keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jakrapop_nlu/lib/python3.9/site-packages/jsonlines/jsonlines.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, type, allow_none, skip_empty, skip_invalid)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m                     yield self.read(\n\u001b[0m\u001b[1;32m    416\u001b[0m                         \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_none\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                     )\n",
      "\u001b[0;32m~/.conda/envs/jakrapop_nlu/lib/python3.9/site-packages/jsonlines/jsonlines.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, type, allow_none, skip_empty)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mJSONValue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0morig_exc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             exc = InvalidLineError(\n",
      "\u001b[0;32m~/.conda/envs/jakrapop_nlu/lib/python3.9/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jakrapop_nlu/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jakrapop_nlu/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "from IPython.display import clear_output\n",
    "\n",
    "count_matched = 0\n",
    "count_posts = 0\n",
    "matched_id = []\n",
    "\n",
    "dataset = ['training', 'validation', 'testing'] # validation , testing\n",
    "output_path = '../data_time/raw_all.csv'\n",
    "\n",
    "for ds in dataset :\n",
    "    filepath = f'../OP_datasets/RSDD/{ds}'\n",
    "    \n",
    "\n",
    "    header = ['user_id', 'created_time', 'text']\n",
    "    with jsonlines.open(filepath) as reader:\n",
    "        \n",
    "        for obj in reader:     \n",
    "            my_dict = obj[0] # dict containing 'id', 'label, 'posts' as keys\n",
    "            user_id = my_dict['id']\n",
    "            \n",
    "            if user_id in all_user_id :\n",
    "                count_matched += 1\n",
    "                matched_id.append(user_id)\n",
    "                \n",
    "                for each_post in my_dict['posts']:\n",
    "                    count_posts += 1\n",
    "                    created_time = each_post[0]\n",
    "                    text         = each_post[1]\n",
    "                    text = ' '.join(str(text).split()) # remove consecutive whitespace \\n \\t \\s HERE instead of the dataframe later\n",
    "                    row = [user_id, created_time, text]\n",
    "                    # save_result_csv( header, row, output_path)\n",
    "            \n",
    "print(count_matched)\n",
    "print(count_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "missing_id = []\n",
    "for id in all_user_id:\n",
    "    if id not in matched_id:\n",
    "        missing_id.append(id)\n",
    "print(len(missing_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    matched in 'training' = 76\n",
    "    matched in 'validation' = 69\n",
    "    matched in 'testing' = 68\n",
    "    Matched Total = 213\n",
    "\n",
    "    missing = 28\n",
    "\n",
    "    213 + 28 = 241 (still 3 missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Posts from Specific Timeframe\n",
    "( 1/ 2/ 3/ months after declared tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372081, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "raw_text = pd.read_csv('../data_time/depression/raw_all.csv', sep='|', header = 0, lineterminator='\\n', dtype= str, index_col=False)\n",
    "raw_text[\"user_id\"] = raw_text['user_id'].apply(pd.to_numeric)\n",
    "raw_text[\"created_time\"] = raw_text['created_time'].apply(lambda x: datetime.fromtimestamp(int(x)))\n",
    "print(raw_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "saved to :  ./data_time/raw_1m.csv\n",
      "18883\n",
      "241\n",
      "28\n",
      "2\n",
      "saved to :  ./data_time/raw_2m.csv\n",
      "34626\n",
      "241\n",
      "28\n",
      "3\n",
      "saved to :  ./data_time/raw_3m.csv\n",
      "46892\n",
      "241\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "months = [1, 2, 3]\n",
    "header = ['user_id', 'text']\n",
    "\n",
    "for month in months:\n",
    "    output_path = f'../data_time/raw_{month}m.csv'\n",
    "\n",
    "    count_posts = 0\n",
    "    count_match = 0\n",
    "    count_no_match = 0\n",
    "\n",
    "    for user_id, user_declare_time in user_time.items():\n",
    "        # print(user_id, user_declare_time)\n",
    "        all_this_user = raw_text.loc[raw_text['user_id'] == user_id]\n",
    "        if all_this_user.shape[0] == 0:\n",
    "            count_no_match += 1\n",
    "            # print('no match found')\n",
    "            \n",
    "        count_match += 1\n",
    "        # print(all_this_user.shape)\n",
    "        \n",
    "        last_valid_time = user_declare_time + relativedelta(months=month)\n",
    "        # print(user_declare_time)\n",
    "        # print(last_valid_time)\n",
    "        \n",
    "        valid_posts = all_this_user.loc[all_this_user['created_time'] >= user_declare_time]\n",
    "        valid_posts = valid_posts.loc[valid_posts['created_time'] <= last_valid_time]\n",
    "        \n",
    "        # print(valid_posts.shape)\n",
    "        \n",
    "        for idx in range(valid_posts.shape[0]):\n",
    "            count_posts += 1\n",
    "            user_id = valid_posts.iloc[idx,:].loc['user_id']\n",
    "            text = valid_posts.iloc[idx,:].loc['text']\n",
    "            text = ' '.join(str(text).split()) # IMPORTANT!! remove consecutive whitespace \\n \\t \\s\n",
    "            row = [user_id, text]\n",
    "            save_result_csv( header,  row,  output_path)\n",
    "        \n",
    "    print(month)\n",
    "    print(\"saved to : \", output_path)\n",
    "    print(count_posts)\n",
    "    print(count_match)\n",
    "    print(count_no_match)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1 Month\n",
    "    18883 posts\n",
    "    241 users\n",
    "    \n",
    "    2 Months\n",
    "    34626 posts\n",
    "    241 users\n",
    "    \n",
    "    3 Months\n",
    "    46892 posts\n",
    "    241 users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a54ebe46dc67c0b0016e368835037c988a8dce633f341e79a61a84613b212514"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
